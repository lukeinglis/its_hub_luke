# Environment variables for ITS demo
# Copy this file to .env and fill in your values

# ============================================================================
# OpenAI API (Required for GPT models and LLM judge)
# ============================================================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# ============================================================================
# Google Cloud Vertex AI (Optional - for Claude and Gemini via Vertex AI)
# ============================================================================
# Setup steps:
# 1. Set up Google Cloud Project: https://console.cloud.google.com/
# 2. Enable Vertex AI API: gcloud services enable aiplatform.googleapis.com
# 3. Enable required APIs:
#    - For Claude: Visit https://console.cloud.google.com/vertex-ai/publishers/anthropic
#    - For Gemini: Already available on Vertex AI by default
# 4. Set up authentication (choose ONE method):
#
#    Option A - Application Default Credentials (recommended for local dev):
#      gcloud auth application-default login
#
#    Option B - Service Account Key:
#      GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/service-account-key.json
#
# 5. Set your project ID and location:
VERTEX_PROJECT=your-gcp-project-id
VERTEX_LOCATION=us-central1

# ============================================================================
# OpenRouter (Optional - access to Llama, Mistral, Phi, Qwen, Gemma, etc.)
# ============================================================================
# One API key gives access to dozens of open-source models.
# Great for ITS demos with small/weak models (3B-9B parameters).
# 1. Sign up at https://openrouter.ai/keys
# 2. Create an API key and paste it below:
# OPENROUTER_API_KEY=sk-or-v1-your-key-here

# ============================================================================
# IBM Granite Models (Optional - self-hosted via vLLM or OpenAI-compatible endpoint)
# ============================================================================
# Granite 4.0 and 3.3 models from: https://huggingface.co/ibm-granite
# To use Granite models:
# 1. Start vLLM server: vllm serve ibm-granite/granite-4.0-8b-instruct --port 8100
# 2. Uncomment and set these variables:
GRANITE_BASE_URL=http://localhost:8100/v1
GRANITE_API_KEY=NO_API_KEY

# ============================================================================
# Local vLLM server (Optional)
# ============================================================================
# VLLM_BASE_URL=http://localhost:8100/v1
# VLLM_API_KEY=NO_API_KEY
# VLLM_MODEL_NAME=your-model-name
# VLLM_MODEL_SIZE=Small  # Optional: Small, Medium, Large, or parameter count like "7B"
