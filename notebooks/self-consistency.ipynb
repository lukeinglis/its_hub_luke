{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd7d8ca",
   "metadata": {},
   "source": [
    "# Self-Consistency Algorithm Demo\n",
    "This notebook demonstrates the Self-Consistency algorithm for mathematical reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefba3d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from its_hub.lms import OpenAICompatibleLanguageModel\n",
    "from its_hub.utils import SAL_STEP_BY_STEP_SYSTEM_PROMPT\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Main example: OpenAI API endpoint with gpt-4o-mini\n",
    "lm = OpenAICompatibleLanguageModel(\n",
    "    endpoint=\"https://api.openai.com/v1\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  # Load API key from environment\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    system_prompt=SAL_STEP_BY_STEP_SYSTEM_PROMPT,\n",
    "    is_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: vLLM local endpoint (commented out)\n",
    "# lm = OpenAICompatibleLanguageModel(\n",
    "#     endpoint=\"http://localhost:8000/v1\",\n",
    "#     api_key=\"NO_API_KEY\",\n",
    "#     model_name=\"qwen2-math-1.5b-instruct\",\n",
    "#     system_prompt=SAL_STEP_BY_STEP_SYSTEM_PROMPT,\n",
    "#     is_async=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical problem to solve\n",
    "prompt = r\"Let $a$ be a positive real number such that all the roots of \\[x^3 + ax^2 + ax + 1 = 0\\]are real. Find the smallest possible value of $a.$\"\n",
    "\n",
    "# Generate response using the proper format\n",
    "from its_hub.types import ChatMessages\n",
    "\n",
    "chat_messages = ChatMessages.from_prompt_or_messages(prompt)\n",
    "response = lm.generate(chat_messages.to_batch(1))[0]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boxed(s: str) -> str:\n",
    "    import re\n",
    "    # find all occurrences of \\boxed{...}\n",
    "    boxed_matches = re.findall(r'\\\\boxed\\{([^{}]+(?:\\{[^{}]*\\}[^{}]*)*)\\}', s)\n",
    "    # return the last match if any were found\n",
    "    return boxed_matches[-1] if boxed_matches else \"\"\n",
    "\n",
    "print(extract_boxed(response['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6607ac9",
   "metadata": {},
   "source": [
    "## Self-Consistency Algorithm\n",
    "Now we'll use the Self-Consistency algorithm to improve the answer quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa031310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from its_hub.algorithms import SelfConsistency\n",
    "\n",
    "# Set computational budget for scaling\n",
    "budget = 4\n",
    "\n",
    "scaling_alg = SelfConsistency(extract_boxed)\n",
    "\n",
    "scaling_result = scaling_alg.infer(\n",
    "    lm, prompt, budget, return_response_only=False\n",
    ")\n",
    "\n",
    "print(\"######## Self-Consistency Result ########\")\n",
    "print(scaling_result.the_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5498e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"######## Extracted Response Counts ########\")\n",
    "print(scaling_result.response_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5b95a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e259b6d7",
   "metadata": {},
   "source": [
    "## Self-Consistency Algorithm for Tool Calls\n",
    "We have hierarchical tool-voting support in Self-Consistency algorithm\n",
    "It first votes on tool names, and then on tool arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from its_hub.types import ChatMessage, ChatMessages\n",
    "\n",
    "# Tool schema (OpenAI-style dicts)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"Perform arithmetic calculations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Mathematical expression to evaluate\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# ChatMessages instance with system + user\n",
    "tool_call_messages = ChatMessages([\n",
    "    ChatMessage(\n",
    "        role=\"system\",\n",
    "        content=\"You are a precise calculator. Always use the calculator tool for arithmetic and format your final answer as \\\\boxed{result}.\"\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        content=\"What is 847 * 293 + 156?\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use hierarchical tool voting\n",
    "scaling_alg_tool = SelfConsistency(tool_vote=\"tool_hierarchical\")\n",
    "\n",
    "budget = 5\n",
    "scaling_result = scaling_alg_tool.infer(\n",
    "    lm, tool_call_messages, budget, return_response_only=False, tools=tools, tool_choice=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092e4bb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"######## Self-Consistency Result ########\")\n",
    "print(scaling_result.the_one)\n",
    "\n",
    "print(\"######## Tool Call Response Counts ########\")\n",
    "print(scaling_result.response_counts)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "all"
  },
  "kernelspec": {
   "display_name": "inference_time_scaling-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
